{
  "fields": {
    "version_num": 0,
    "title": "Gibbs sampling",
    "pointers": "* Gibbs sampling can be viewed as a  [special case of Metropolis-Hastings](gibbs_as_mh) .\n* Naive Gibbs sampling is often very slow to mix. Some improved versions include:\n**  [block Gibbs sampling](block_gibbs_sampling) , where we sample multiple variables at a time\n**  [collapsed Gibbs sampling](collapsed_gibbs_sampling) , where some of the variables are integrated out in closed form\n*  [Slice sampling](slice_sampling)  is a special case of Gibbs sampling, good for sampling from univariate distributions with no closed-form sampler\n* We can  [analyze the mixing rate](analyzing_mcmc_mixing)  using spectral graph theory.",
    "tags": ["machinelearning", "pgm"],
    "learn_time": 0.8573179365356832,
    "summary": "Gibbs sampling is a Markov Chain Monte Carlo (MCMC) algorithm where each random variable is iteratively resampled from its conditional distribution given the remaining variables. It's a simple and often highly effective approach for performing posterior inference in probabilistic models.\n",
    "last_mod": "2014-08-30T03:22:13.600Z",
    "tag": "gibbs_sampling",
    "exercises": null,
    "is_shortcut": false,
    "software": null
  },
  "model": "graph.concept",
  "pk": "n4mru8iv"
}
