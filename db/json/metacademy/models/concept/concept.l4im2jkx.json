{
  "fields": {
    "version_num": 0,
    "title": "Bayesian parameter estimation: multivariate Gaussians",
    "pointers": "* These techniques are used in various models, including:\n**  [Bayesian linear regression](bayesian_linear_regression)\n**  [Bayesian mixture of Gaussians](bayesian_mixture_of_gaussians)\n* The  [Wishart process](wishart_process)  allows us to model dependencies between different Wishart-distributed random variables.\n* When there's not enough data to estimate a full covariance matrix, here are some related models with more structure:\n**  [principal component analysis (PCA)](principal_component_analysis)\n**  [factor analysis](factor_analysis)\n**  [probabilistic matrix factorization (PMF)](probabilistic_matrix_factorization)\n**  [sparse Gaussian graphical models](learning_sparse_gaussian_graphical_models)",
    "tags": ["bayesianstats", "machinelearning"],
    "learn_time": 1.1728364885339997,
    "summary": "Using the Bayesian framework, we can infer the posterior over the mean vector of a multivariate Gaussian, the covariance matrix, or both. Since multivariate Gaussians are widely used in probabilistic modeling, the computations that go into this are common motifs in Bayesian machine learning more generally.\n",
    "last_mod": "2014-08-31T00:11:15.312Z",
    "tag": "bayes_param_multivariate_gaussian",
    "exercises": null,
    "is_shortcut": false,
    "software": null
  },
  "model": "graph.concept",
  "pk": "l4im2jkx"
}
